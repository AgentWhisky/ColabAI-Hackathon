<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[SHF: Medium:DILSE: Codesigning Decentralized Incremental Learning System via Streaming Data Summarization on Edge]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>01/01/2024</AwardEffectiveDate>
<AwardExpirationDate>07/31/2026</AwardExpirationDate>
<AwardTotalIntnAmount>1200000.00</AwardTotalIntnAmount>
<AwardAmount>478773</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Almadena Chtchelkanova</SignBlockName>
<PO_EMAI>achtchel@nsf.gov</PO_EMAI>
<PO_PHON>7032927498</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Various emerging fields, such as connected autonomous vehicles and smart home analytics, have ushered in an era of Artificial Intelligence (AI) on Internet of Things devices. However, with the proliferation of modern edge devices characterized by limited storage, heterogeneous capabilities, dynamic network connection, and growing concerns of data privacy, it will become impractical to scale and update the current mainstream centralized machine learning (ML) models, leading to large latency delays, energy dissipation, and potentially outdated models with degraded performance. Hence, it has become paramount to efficiently process the inherently decentralized data streams on-device, i.e., closest to their sources without sharing and accumulating the raw training samples on a centralized server.  While Federated learning (FL) has emerged to bring ML models, its global model updated at the server by aggregating local models can lead to poor model convergence and requires compromises between model accuracy and available resources on heterogeneous resource-constrained edge devices. Moreover, FL has not yet been designed for handling streaming data generated on the edge. This project aims to open up a new paradigm for developing powerful ML models by combining the best of both worlds of centralized ML and decentralized FL, and thus push forward the frontier of unleashing the great promise of AI to transform human life. The outcomes from this project will lead to new course materials spanning several areas of ML (e.g., decentralized optimization, computer architecture, and edge computing systems) and open-education resources that aim to attract diverse groups of students and eventually deliver a platform for inclusion and innovation.&lt;br/&gt;&lt;br/&gt;This project is to bridge Centralized ML and decentralized FL, considering the salient streaming and statistical characteristics of data combined with widespread device and network heterogeneity. The key contributions are to develop rigorous foundations for the new decentralized ML training setup in: (1) creating new algorithms for on-device summarization of streaming data to reduce memory cost and improve the processing latency, while preserving privacy; (2) performing decentralized optimization and communication under the heterogeneity of devices in a communication network; and (3) co-designing energy-efficient hardware architecture and algorithm for accelerating streaming data summarization with real-time inference, and developing decentralized incremental learning via streaming data summarization on the edge on a network of real heterogeneous edge devices for system evaluation, validation, and demonstration while promoting green AI.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/24/2024</MinAmdLetterDate>
<MaxAmdLetterDate>07/24/2024</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2434166</AwardID>
<Investigator>
<FirstName>Yingyan</FirstName>
<LastName>Lin</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Yingyan C Lin</PI_FULL_NAME>
<EmailAddress><![CDATA[celine.lin@gatech.edu]]></EmailAddress>
<NSF_ID>000758624</NSF_ID>
<StartDate>07/24/2024</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[Georgia Tech Research Corporation]]></Name>
<CityName>ATLANTA</CityName>
<ZipCode>303186395</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress><![CDATA[926 DALNEY ST NW]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>GA05</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>EMW9FC8J3HN4</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>GEORGIA TECH RESEARCH CORP</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>EMW9FC8J3HN4</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Georgia Tech Research Corporation]]></Name>
<CityName>ATLANTA</CityName>
<StateCode>GA</StateCode>
<ZipCode>303186395</ZipCode>
<StreetAddress><![CDATA[926 DALNEY ST NW]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>05</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>GA05</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>779800</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7924</Code>
<Text>MEDIUM PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7942</Code>
<Text>HIGH-PERFORMANCE COMPUTING</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Fund>
<Code>01002223DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2022~478773</FUND_OBLG>
</Award>
</rootTag>
