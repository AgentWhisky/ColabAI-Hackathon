<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[Perception and imitation of speech and song:  The parameter reweighting hypothesis]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2024</AwardEffectiveDate>
<AwardExpirationDate>07/31/2027</AwardExpirationDate>
<AwardTotalIntnAmount>398796.00</AwardTotalIntnAmount>
<AwardAmount>398796</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Betty Tuller</SignBlockName>
<PO_EMAI>btuller@nsf.gov</PO_EMAI>
<PO_PHON>7032927238</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The ability to imitate is critical for learning to speak or sing. Not yet understood is why this skill comes easily for most but is quite difficult for others. Although speech and song imitation involve coordinating the same motor and auditory systems, there are important differences in the signal, the context in which production is used, and possibly individual differences in ability. This project tests whether these differences, though striking, emerge from a common system for vocal motor control. Differences across speech and song may involve adapting this common system to communicative demands. The idea that speech and song rely on a shared representation has important implications in therapeutic settings, supporting the use of interventions that use melody and song to bootstrap speech rehabilitation.  &lt;br/&gt;&lt;br/&gt;The specific hypothesis underlying this project is that people adapt vocal motor control based on the acoustical structure of the pattern they are producing, as well as the contextual demands of the current situation. The work evaluates whether producers “reweight” the importance of different acoustical parameters (e.g., pitch stability, rate of production) based on these factors. Acoustic parameters are manipulated along a speech-to-song continuum (e.g., the amount of variability within a tone), as well as contextual information that may signal a more speech-like or more song-like context (e.g., vocal synchronization with another person versus turn-taking). Participants vocally imitate pitch patterns under these different circumstances or rate whether an auditory pattern sounds more like speech or more like song. The issue is whether speech/song differences reflect a continuum rather than a strict categorical distinction in both perception and production. Also assessed is whether vocal pitch control varies across features associated with speech and song based on the surrounding context.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/16/2024</MinAmdLetterDate>
<MaxAmdLetterDate>07/16/2024</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.075</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2419763</AwardID>
<Investigator>
<FirstName>Peter</FirstName>
<LastName>Pfordresher</LastName>
<PI_MID_INIT>Q</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Peter Q Pfordresher</PI_FULL_NAME>
<EmailAddress><![CDATA[pqp@buffalo.edu]]></EmailAddress>
<NSF_ID>000238988</NSF_ID>
<StartDate>07/16/2024</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[SUNY at Buffalo]]></Name>
<CityName>AMHERST</CityName>
<ZipCode>142282577</ZipCode>
<PhoneNumber>7166452634</PhoneNumber>
<StreetAddress><![CDATA[520 LEE ENTRANCE STE 211]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>26</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY26</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>LMCJKRFW5R81</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>GMZUKXFDJMA9</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[SUNY at Buffalo]]></Name>
<CityName>Buffalo</CityName>
<StateCode>NY</StateCode>
<ZipCode>142604110</ZipCode>
<StreetAddress><![CDATA[362 Park Hall]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>26</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY26</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>725200</Code>
<Text>Perception, Action &amp; Cognition</Text>
</ProgramElement>
<ProgramReference>
<Code>5913</Code>
<Text>BRAZIL</Text>
</ProgramReference>
<ProgramReference>
<Code>5946</Code>
<Text>UNITED KINGDOM</Text>
</ProgramReference>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Fund>
<Code>01002425DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2024~398796</FUND_OBLG>
</Award>
</rootTag>
