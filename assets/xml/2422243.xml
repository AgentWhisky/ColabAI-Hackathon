<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[I-Corps:  Translation potential of minimally invasive tubular retractors to maximize visualization in spine operations]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>04/01/2024</AwardEffectiveDate>
<AwardExpirationDate>03/31/2025</AwardExpirationDate>
<AwardTotalIntnAmount>50000.00</AwardTotalIntnAmount>
<AwardAmount>50000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>15030000</Code>
<Directorate>
<Abbreviation>TIP</Abbreviation>
<LongName>Dir for Tech, Innovation, &amp; Partnerships</LongName>
</Directorate>
<Division>
<Abbreviation>TI</Abbreviation>
<LongName>Translational Impacts</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ruth Shuman</SignBlockName>
<PO_EMAI>rshuman@nsf.gov</PO_EMAI>
<PO_PHON>7032922160</PO_PHON>
</ProgramOfficer>
<AbstractNarration>The broader impact of this I-Corps project is the development of a system to aid surgeons performing spinal surgery.  Currently, minimally invasive surgical techniques are becoming the primary method by which spinal pathologies and deformities are treated. However, the small incision sizes inherent in these approaches prevents optimal visualization of the operating area, and these procedures require the use of cumbersome surgical microscopes at awkward angles, increasing the risk of surgical error and negatively impacting surgical ergonomics.  This solution is a camera system with integrated artificial intelligence (AI) software that subtracts obstructive tool shafts from the field of view, and also highlights tooltips and vital anatomy for the surgeon in real time.  By allowing for maximal visualization in minimally invasive settings, this technology may increase the accessibility, ease, and reliability of these procedures. In addition, the AI software and modular hardware create a foundation for a database of surgical procedures that may be used to train other algorithms to be applied in a range of surgical settings including laparoscopic, endoscopic, and robotic techniques.&lt;br/&gt;&lt;br/&gt;This I-Corps project utilizes experiential learning coupled with a first-hand investigation of the industry ecosystem to assess the translation potential of the technology. The solution is based on the previous development of a camera system with integrated artificial intelligence (AI) software that maximizes the visualization of minimally invasive spine operations through minimally invasive tubular retractors (MITRs).  Minimally invasive tubular retractors (MITRs) are metal tubes with diameters ranging from 14-22 mm that are used as operating corridors in minimally invasive spine surgeries. They suffer from limited visibility, awkward tool angling, and reliance on cumbersome surgical microscopes. This solution utilizes an array of cameras that focus down the MITRâ€™s operating corridor and capture the operating field from multiple angles. These views are analyzed by the integrated AI software to produce a single live image that removes obstructive and unwanted parts of surgeon tools (e.g., tool shaft) while retaining other necessary components (e.g., tooltip). Specifically, the software aims to combine the array of camera inputs into a singular real-time video output that is segmented and inpainted to increase the surgeons view by over 30%. This is achieved with the help of a specialized deep learning computer vision model that enables the software to identify (via segmentation) and crop out (via inpainting) obstructive objects (tool shafts) within the video feed. Ultimately, this visually maximized image is displayed on a heads-up screen in front of the surgeon, improving outcomes by maximizing the visualization of the operating area and the ergonomics of the procedure.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>03/26/2024</MinAmdLetterDate>
<MaxAmdLetterDate>03/26/2024</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.084</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2422243</AwardID>
<Investigator>
<FirstName>Kevin</FirstName>
<LastName>Costa</LastName>
<PI_MID_INIT>D</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Kevin D Costa</PI_FULL_NAME>
<EmailAddress><![CDATA[kevin.costa@mssm.edu]]></EmailAddress>
<NSF_ID>000092198</NSF_ID>
<StartDate>03/26/2024</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[Icahn School of Medicine at Mount Sinai]]></Name>
<CityName>NEW YORK</CityName>
<ZipCode>100296504</ZipCode>
<PhoneNumber>2128248300</PhoneNumber>
<StreetAddress><![CDATA[1 GUSTAVE L LEVY PL]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY13</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>C8H9CNG1VBD9</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>C8H9CNG1VBD9</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Icahn School of Medicine at Mount Sinai]]></Name>
<CityName>NEW YORK</CityName>
<StateCode>NY</StateCode>
<ZipCode>100296504</ZipCode>
<StreetAddress><![CDATA[1 GUSTAVE L LEVY PL]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>13</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY13</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>802300</Code>
<Text>I-Corps</Text>
</ProgramElement>
<ProgramReference>
<Code>5345</Code>
<Text>BIOMEDICAL ENGINEERING</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Fund>
<Code>01002425DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2024~50000</FUND_OBLG>
</Award>
</rootTag>
