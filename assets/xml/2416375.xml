<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[Collaborative Research: FuSe: Metaoptics-Enhanced Vertical Integration for Versatile In-Sensor Machine Vision]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>10/15/2023</AwardEffectiveDate>
<AwardExpirationDate>09/30/2026</AwardExpirationDate>
<AwardTotalIntnAmount>1100000.00</AwardTotalIntnAmount>
<AwardAmount>327854</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sankar Basu</SignBlockName>
<PO_EMAI>sabasu@nsf.gov</PO_EMAI>
<PO_PHON>7032927843</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Vision is perhaps the most important human perception, as the majority of the brain’s cognitive function is dedicated to processing visual information. Despite recent advancements, today’s vision sensors remain quite primitive when compared to the superior ability of human visual perception. Moreover, the rapid development of deep learning and artificial intelligence (AI) has unleashed a new wave of machine vision, where increasing amounts of image data are generated and consumed, not by humans, but by edge devices to perform intelligent tasks such as classification, recognition, and perception. Inspired by the biological system and motivated by the huge demand of machine vision, this project investigates an integrated and holistic approach to building versatile vision systems that can be tailored for domain-specific tasks. It aims to create a vertically-integrated design stack for vision sensors across optics, image sensors, and vision processors. The project is expected to herald a new paradigm of AI-driven vision systems and demonstrate technology to address pivotal engineering challenges from real-time visual adaptivity in self-driving cars to near-zero energy efficiency in persistent environmental monitoring. In addition, the project’s education and workforce development activities foster an open-source hardware community to boost accessibility and deepen collaboration beyond the traditional discipline divides, as well as to build up the capacity of domestic talents in vision sensor industry, critical to national security and supply chain safety. &lt;br/&gt;&lt;br/&gt;The research objective of this project is to create the scientific and engineering foundations for a novel machine vision system that explores the hybrid integration of nanophotonic metamaterials and complementary metal-oxide semiconductor (CMOS) circuits and synergistically leverages the intrinsic computing capability of computational metasurface and analog-domain encoder embedded inside the image sensors. Our principled approach to abstracting design knobs and modeling interactions and tradeoffs across the system layers and physical domains will inform future “More than Moore” multi-physics semiconductor device integration. We will delve into the key concept of optimally distributing computation along the processing pipeline with complementary intrinsic physical-domain operations. Our end-to-end design framework is deliberately created to bridge the divide between modeling/simulation infrastructure and design toolchains across multiple heterogeneous physical domains. The core principles of embedding machine-learning-enabled feature selection with optical/electrical vertical integration could have a major impact on the design of sensor-rich intelligent physical platforms where resource constraints coincide with strict latency requirements. The technology developed in this project will turbocharge AI-enabled hardware to satisfy the tremendous computational demand imposed by data proliferation, broadly benefiting a range of burgeoning industries such as machine vision as a service, smart IoT infrastructure, data-driven sensing and imaging.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>02/12/2024</MinAmdLetterDate>
<MaxAmdLetterDate>05/15/2024</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070, 47.084</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2416375</AwardID>
<Investigator>
<FirstName>Xuan</FirstName>
<LastName>Zhang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Xuan Zhang</PI_FULL_NAME>
<EmailAddress><![CDATA[xuan.zhang@northeastern.edu]]></EmailAddress>
<NSF_ID>000700363</NSF_ID>
<StartDate>02/12/2024</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[Northeastern University]]></Name>
<CityName>BOSTON</CityName>
<ZipCode>021155005</ZipCode>
<PhoneNumber>6173733004</PhoneNumber>
<StreetAddress><![CDATA[360 HUNTINGTON AVE]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MA07</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>HLTMVS2JZBS6</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>NORTHEASTERN UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Northeastern University]]></Name>
<CityName>BOSTON</CityName>
<StateCode>MA</StateCode>
<ZipCode>021155005</ZipCode>
<StreetAddress><![CDATA[360 HUNTINGTON AVE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>216Y00</Code>
<Text>FuSe-Future of Semiconductors</Text>
</ProgramElement>
<ProgramElement>
<Code>241Y00</Code>
<Text>NSF-Intel Semiconductr Partnrs</Text>
</ProgramElement>
<ProgramElement>
<Code>254Y00</Code>
<Text>NSF-Samsung Partnership</Text>
</ProgramElement>
<ProgramElement>
<Code>255Y00</Code>
<Text>NSF-IBM Partnership</Text>
</ProgramElement>
<ProgramReference>
<Code>7945</Code>
<Text>DES AUTO FOR MICRO &amp; NANO SYST</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Fund>
<Code>4082PYXXDB</Code>
<Name><![CDATA[NSF TRUST FUND]]></Name>
<FUND_SYMB_ID>048960</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>01002324DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<Fund>
<Code>4082CYXXDB</Code>
<Name><![CDATA[NSF TRUST FUND]]></Name>
<FUND_SYMB_ID>048960</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2023~327854</FUND_OBLG>
</Award>
</rootTag>
