<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[Uncertainty quantification for iterative algorithms]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/01/2024</AwardEffectiveDate>
<AwardExpirationDate>06/30/2027</AwardExpirationDate>
<AwardTotalIntnAmount>225000.00</AwardTotalIntnAmount>
<AwardAmount>74675</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tapabrata Maiti</SignBlockName>
<PO_EMAI>tmaiti@nsf.gov</PO_EMAI>
<PO_PHON>7032925307</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Learning from data is performed by iterative algorithms throughout statistics and machine learning. Iterative learning algorithms find models that best fit the labeled training data, in order to make predictions on unseen and unlabeled data. These iterative algorithms are run in computers until an optimality criterion is met or exhausting computational resources. Empirical evidence suggests that terminating algorithms early, before convergence, enhances prediction performance on unseen data in certain learning scenarios.  The project aims to develop theory to explain this early-stopping phenomenon, as well as practical methodologies to determine the optimal early iteration for best predictions on unseen data and saving computational resources. The research will involve students at both undergraduate and graduate levels.&lt;br/&gt;&lt;br/&gt;Modern estimators in statistics and machine learning are ubiquitously defined as solutions to optimization problems, whether convex or nonconvex.  These optimization problems are solved iteratively using gradient descent and its accelerated variants, or proximal iterative schemes if the objective function is non-smooth. On the other hand, inferential methodologies such as debiasing, the construction of confidence intervals in regression models or estimation of the generalization error have so far been developed assuming algorithm convergence.  This research will bridge this gap and develop inferential methodologies for algorithm iterates, including at a constant number of iterations or far from convergence. The project aims to develop estimators of the generalization error of the iterates, with application to early stopping to minimize population error.  The project further plans to equip iterative algorithms with confidence intervals and hypothesis tests valid throughout the trajectory, allowing practitioners to perform hypothesis rejections and discoveries at early iterations, without relying on algorithm convergence.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/14/2024</MinAmdLetterDate>
<MaxAmdLetterDate>06/14/2024</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.049</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2413679</AwardID>
<Investigator>
<FirstName>Pierre</FirstName>
<LastName>Bellec</LastName>
<PI_MID_INIT>C</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Pierre C Bellec</PI_FULL_NAME>
<EmailAddress><![CDATA[pcb71@stat.rutgers.edu]]></EmailAddress>
<NSF_ID>000734408</NSF_ID>
<StartDate>06/14/2024</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[Rutgers University New Brunswick]]></Name>
<CityName>NEW BRUNSWICK</CityName>
<ZipCode>089018559</ZipCode>
<PhoneNumber>8489320150</PhoneNumber>
<StreetAddress><![CDATA[3 RUTGERS PLZ]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NJ12</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>M1LVPE5GLSD9</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>RUTGERS, THE STATE UNIVERSITY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Rutgers University New Brunswick]]></Name>
<CityName>Piscataway</CityName>
<StateCode>NJ</StateCode>
<ZipCode>088548019</ZipCode>
<StreetAddress><![CDATA[110 Frelinghuysen Road]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NJ06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>126900</Code>
<Text>STATISTICS</Text>
</ProgramElement>
<ProgramReference>
<Code>1269</Code>
<Text>STATISTICS</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Fund>
<Code>01002425DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2024~74675</FUND_OBLG>
</Award>
</rootTag>
