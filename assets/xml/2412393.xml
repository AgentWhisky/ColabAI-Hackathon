<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[ERI: Distributed Learning in Regulation of UAV Communication Networks with Dynamic UAV Lineup]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>11/15/2023</AwardEffectiveDate>
<AwardExpirationDate>06/30/2025</AwardExpirationDate>
<AwardTotalIntnAmount>192785.00</AwardTotalIntnAmount>
<AwardAmount>125926</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07010000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>ECCS</Abbreviation>
<LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Anthony Kuh</SignBlockName>
<PO_EMAI>akuh@nsf.gov</PO_EMAI>
<PO_PHON>7032924714</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This award is funded in whole or in part under the American Rescue Plan Act of 2021 (Public Law 117-2).&lt;br/&gt;&lt;br/&gt;Unmanned aerial vehicles, or drones, have been demonstrating impressive potentials in next generation wireless communications. Compared to the terrestrial cellular base stations, drones equipped with wireless transceivers can serve as mobile base stations, and stand out in providing highly on-demand services with flexible 3D mobility, better wireless connectivity with higher chance of Line-of-Sight links, and much lower deployment cost with almost infrastructure-free network construction. Promising as it is, drone based communication networks still face fundamental regulation challenges: i) as drones are highly mobile, the dynamically changing network topology may make it unpractical for a centralized control unit to collect complete network information and make collective decisions; ii) the environment in which drones operate may be dynamically changing or unexplored without a priori knowledge of the environment modeling, making the conventional optimization or rule-based methods hardly applicable; iii) the research is still embryonic on how to optimally regulate the drone network when the lineup of the serving drones dynamically change, which, however, will be a common event in realistic implementation. To this end, this proposal is aimed to crack the nut of the above identified issues, and develop an effective framework for distributed network regulation solutions that are environment-model-free and well adaptive to the dynamic drone lineup. The research outcomes are expected to provide valuable inspirations and benchmarking to the distributed, scalable, and artificial-intelligence powered management of aerial access communication networks under a dynamic network setup. Such networks will be embraced as a key component in the larger-scope Space-Air-Ground Integrated Networks for the beyond-5G mobile telecommunications. The success of the project will potentially contribute to the leadership and competence of the United States worldwide in future generation mobile telecommunications as well as elevating national communication welfare with more integrated and on-demand communication infrastructure.&lt;br/&gt;&lt;br/&gt;In this project, multi-agent reinforcement learning will be applied to establish a distributed and model-free network regulation framework. The framework will feature strong capability in making sequential decisions in complex time-varying environments. Under the developed framework, the project aims to investigate how the drone communication networks should responsively handle and further proactively control the dynamic change of the drone lineup in a distributed yet coordinated manner. Specifically, responsive strategies will be first designed for a general drone communication network. The strategies will jointly optimize the radio resource management and trajectory design for the drones when the drone lineup change dynamically. The learning algorithm design will be investigated with different levels of inter-drone information exchange. The learning exploration will be promoted by adopting the structure of asynchronous parallel computing. The network will be prototyped leveraging on programmable drone products and simple-yet-effective communication protocols. To move one step further, proactive control strategies will be derived for the solar-powered self-sustainable drone communication network, which proactively control the quit and join-in of the drones by pre-shaping their solar-charging plan. The strategies will consider dynamic user spatial and traffic distributions by combining Fourier analysis, Long-Short Term Memory and Gaussian process regression for distribution prediction, and enabling predicting while learning to significantly reduce the reinforcement learning complexity. The hybrid cooperative-compete relationship among individual drones will be handled by exploiting Nash Q learning and correlated Q learning. The anxiety on the high-dimension state-action space in learning will be relieved by adopting problem decomposition techniques. The proposed project will advance the research on autonomous regulation of drone communication networks by filling the gaps of missing control strategy design to responsively handle and proactively control the drone lineup change. In addition, the introduction of game theory into the distributed framework makes the research more realistic with diversified autonomy in individual drones. The prototyping plan will complement the simulation evaluation on the time complexity and communication overhead/latency in the real-world implementation.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>04/01/2024</MinAmdLetterDate>
<MaxAmdLetterDate>04/01/2024</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>1</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>2412393</AwardID>
<Investigator>
<FirstName>Ran</FirstName>
<LastName>Zhang</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ran Zhang</PI_FULL_NAME>
<EmailAddress><![CDATA[zhangr43@miamioh.edu]]></EmailAddress>
<NSF_ID>000814005</NSF_ID>
<StartDate>04/01/2024</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name><![CDATA[University of North Carolina at Charlotte]]></Name>
<CityName>CHARLOTTE</CityName>
<ZipCode>282230001</ZipCode>
<PhoneNumber>7046871888</PhoneNumber>
<StreetAddress><![CDATA[9201 UNIVERSITY CITY BLVD]]></StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<StateCode>NC</StateCode>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NC12</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>JB33DT84JNA5</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF NORTH CAROLINA AT CHARLOTTE, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM>N8DMK1K4C2K5</ORG_PRNT_UEI_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of North Carolina at Charlotte]]></Name>
<CityName>CHARLOTTE</CityName>
<StateCode>NC</StateCode>
<ZipCode>282230001</ZipCode>
<StreetAddress><![CDATA[9201 UNIVERSITY CITY BLVD]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>North Carolina</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>12</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NC12</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>180Y00</Code>
<Text>ERI-Eng. Research Initiation</Text>
</ProgramElement>
<ProgramReference>
<Code>4096</Code>
<Text>COMMUNICATIONS RESEARCH</Text>
</ProgramReference>
<ProgramReference>
<Code>7607</Code>
<Text>POWER, CONTROLS &amp; ADAPTIVE NET</Text>
</ProgramReference>
<ProgramReference>
<Code>8888</Code>
<Text>LEARNING &amp; INTELLIGENT SYSTEMS</Text>
</ProgramReference>
<Appropriation>
<Code/>
<Name/>
<APP_SYMB_ID/>
</Appropriation>
<Fund>
<Code>01002223DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2022~125926</FUND_OBLG>
</Award>
</rootTag>
